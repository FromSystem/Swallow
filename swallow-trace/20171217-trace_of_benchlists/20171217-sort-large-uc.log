17/12/17 15:24:20 INFO SparkContext: Running Spark version 2.2.0
17/12/17 15:24:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/17 15:24:21 INFO SparkContext: Submitted application: ScalaSort
17/12/17 15:24:21 INFO SecurityManager: Changing view acls to: hadoop
17/12/17 15:24:21 INFO SecurityManager: Changing modify acls to: hadoop
17/12/17 15:24:21 INFO SecurityManager: Changing view acls groups to:
17/12/17 15:24:21 INFO SecurityManager: Changing modify acls groups to:
17/12/17 15:24:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
17/12/17 15:24:21 INFO Utils: Successfully started service 'sparkDriver' on port 38694.
compressShuffle => [spark.shuffle.compress : false]
17/12/17 15:24:21 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.SnappyCompressionCodec

17/12/17 15:24:21 INFO SparkEnv: Registering MapOutputTracker
17/12/17 15:24:21 INFO SparkEnv: Registering BlockManagerMaster
17/12/17 15:24:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/17 15:24:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/17 15:24:21 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d3bf16b6-ff57-439b-bd09-9f0650fa30d4
17/12/17 15:24:21 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/12/17 15:24:21 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/17 15:24:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/17 15:24:22 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.10.43.130:4040
17/12/17 15:24:22 INFO SparkContext: Added JAR file:/home/hadoop/hadoopTest/HiBench/sparkbench/assembly/target/sparkbench-assembly-6.1-SNAPSHOT-dist.jar at spark://10.10.43.130:38694/jars/sparkbench-assembly-6.1-SNAPSHOT-dist.jar with timestamp 1513495462044
17/12/17 15:24:22 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://cluster209-hadoop-master:7077...
17/12/17 15:24:22 INFO TransportClientFactory: Successfully created connection to cluster209-hadoop-master/10.10.43.130:7077 after 28 ms (0 ms spent in bootstraps)
17/12/17 15:24:22 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20171217152422-0001
17/12/17 15:24:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20171217152422-0001/0 on worker-20171217150826-10.10.43.132-38987 (10.10.43.132:38987) with 4 cores
17/12/17 15:24:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20171217152422-0001/0 on hostPort 10.10.43.132:38987 with 4 cores, 1024.0 MB RAM
17/12/17 15:24:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20171217152422-0001/1 on worker-20171217150835-10.10.43.131-33910 (10.10.43.131:33910) with 4 cores
17/12/17 15:24:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20171217152422-0001/1 on hostPort 10.10.43.131:33910 with 4 cores, 1024.0 MB RAM
17/12/17 15:24:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171217152422-0001/1 is now RUNNING
17/12/17 15:24:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171217152422-0001/0 is now RUNNING
17/12/17 15:24:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34012.
17/12/17 15:24:22 INFO NettyBlockTransferService: Server created on 10.10.43.130:34012
17/12/17 15:24:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/17 15:24:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.10.43.130, 34012, None)
17/12/17 15:24:22 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.43.130:34012 with 366.3 MB RAM, BlockManagerId(driver, 10.10.43.130, 34012, None)
17/12/17 15:24:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.10.43.130, 34012, None)
17/12/17 15:24:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.10.43.130, 34012, None)
17/12/17 15:24:25 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/12/17 15:24:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.43.131:43908) with ID 1
17/12/17 15:24:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.43.132:54404) with ID 0
17/12/17 15:24:25 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.43.131:44517 with 366.3 MB RAM, BlockManagerId(1, 10.10.43.131, 44517, None)
17/12/17 15:24:26 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.43.132:36123 with 366.3 MB RAM, BlockManagerId(0, 10.10.43.132, 36123, None)
17/12/17 15:24:28 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.SnappyCompressionCodec

17/12/17 15:24:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 219.1 KB, free 366.1 MB)
17/12/17 15:24:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 19.9 KB, free 366.1 MB)
17/12/17 15:24:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.10.43.130:34012 (size: 19.9 KB, free: 366.3 MB)
17/12/17 15:24:28 INFO SparkContext: Created broadcast 0 from sequenceFile at IOCommon.scala:44
17/12/17 15:24:29 INFO SparkContext: Starting job: saveAsHadoopFile at IOCommon.scala:63
17/12/17 15:24:29 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.SnappyCompressionCodec

17/12/17 15:24:29 INFO FileInputFormat: Total input paths to process : 8
17/12/17 15:24:29 INFO DAGScheduler: Registering RDD 3 (map at ScalaSort.scala:50)
17/12/17 15:24:29 INFO DAGScheduler: Got job 0 (saveAsHadoopFile at IOCommon.scala:63) with 8 output partitions
17/12/17 15:24:29 INFO DAGScheduler: Final stage: ResultStage 1 (saveAsHadoopFile at IOCommon.scala:63)
17/12/17 15:24:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/12/17 15:24:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/12/17 15:24:29 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at ScalaSort.scala:50), which has no missing parents
17/12/17 15:24:29 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.SnappyCompressionCodec

17/12/17 15:24:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 366.1 MB)
17/12/17 15:24:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.8 KB, free 366.1 MB)
17/12/17 15:24:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.10.43.130:34012 (size: 2.8 KB, free: 366.3 MB)
17/12/17 15:24:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
17/12/17 15:24:29 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at ScalaSort.scala:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
17/12/17 15:24:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 8 tasks
17/12/17 15:24:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 10.10.43.131, executor 1, partition 0, ANY, 4900 bytes)
17/12/17 15:24:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 10.10.43.132, executor 0, partition 1, ANY, 4900 bytes)
17/12/17 15:24:29 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 10.10.43.131, executor 1, partition 2, ANY, 4900 bytes)
17/12/17 15:24:29 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 10.10.43.132, executor 0, partition 3, ANY, 4900 bytes)
17/12/17 15:24:29 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 10.10.43.131, executor 1, partition 4, ANY, 4900 bytes)
17/12/17 15:24:29 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 10.10.43.132, executor 0, partition 5, ANY, 4900 bytes)
17/12/17 15:24:29 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 10.10.43.131, executor 1, partition 6, ANY, 4900 bytes)
17/12/17 15:24:29 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 10.10.43.132, executor 0, partition 7, ANY, 4900 bytes)
17/12/17 15:24:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.10.43.132:36123 (size: 2.8 KB, free: 366.3 MB)
17/12/17 15:24:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.10.43.132:36123 (size: 19.9 KB, free: 366.3 MB)
17/12/17 15:24:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.10.43.131:44517 (size: 2.8 KB, free: 366.3 MB)
17/12/17 15:24:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.10.43.131:44517 (size: 19.9 KB, free: 366.3 MB)
17/12/17 15:24:36 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 7175 ms on 10.10.43.132 (executor 0) (1/8)
17/12/17 15:24:36 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 7239 ms on 10.10.43.132 (executor 0) (2/8)
17/12/17 15:24:36 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 7483 ms on 10.10.43.132 (executor 0) (3/8)
17/12/17 15:24:37 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 7915 ms on 10.10.43.132 (executor 0) (4/8)
17/12/17 15:24:37 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 8111 ms on 10.10.43.131 (executor 1) (5/8)
17/12/17 15:24:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8127 ms on 10.10.43.131 (executor 1) (6/8)
17/12/17 15:24:37 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 8124 ms on 10.10.43.131 (executor 1) (7/8)
17/12/17 15:24:37 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 8207 ms on 10.10.43.131 (executor 1) (8/8)
17/12/17 15:24:37 INFO DAGScheduler: ShuffleMapStage 0 (map at ScalaSort.scala:50) finished in 8.221 s
17/12/17 15:24:37 INFO DAGScheduler: looking for newly runnable stages
17/12/17 15:24:37 INFO DAGScheduler: running: Set()
17/12/17 15:24:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/12/17 15:24:37 INFO DAGScheduler: failed: Set()
17/12/17 15:24:37 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at map at IOCommon.scala:61), which has no missing parents
17/12/17 15:24:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
17/12/17 15:24:37 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.SnappyCompressionCodec

17/12/17 15:24:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 65.7 KB, free 366.0 MB)
17/12/17 15:24:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.0 MB)
17/12/17 15:24:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.10.43.130:34012 (size: 22.9 KB, free: 366.3 MB)
17/12/17 15:24:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/12/17 15:24:37 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at map at IOCommon.scala:61) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
17/12/17 15:24:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 8 tasks
17/12/17 15:24:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 8, 10.10.43.132, executor 0, partition 0, NODE_LOCAL, 4625 bytes)
17/12/17 15:24:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 9, 10.10.43.131, executor 1, partition 1, NODE_LOCAL, 4625 bytes)
17/12/17 15:24:37 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 10, 10.10.43.132, executor 0, partition 2, NODE_LOCAL, 4625 bytes)
17/12/17 15:24:37 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 11, 10.10.43.131, executor 1, partition 3, NODE_LOCAL, 4625 bytes)
17/12/17 15:24:37 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 12, 10.10.43.132, executor 0, partition 4, NODE_LOCAL, 4625 bytes)
17/12/17 15:24:37 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 13, 10.10.43.131, executor 1, partition 5, NODE_LOCAL, 4625 bytes)
17/12/17 15:24:37 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 14, 10.10.43.132, executor 0, partition 6, NODE_LOCAL, 4625 bytes)
17/12/17 15:24:37 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 15, 10.10.43.131, executor 1, partition 7, NODE_LOCAL, 4625 bytes)
17/12/17 15:24:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.10.43.132:36123 (size: 22.9 KB, free: 366.3 MB)
17/12/17 15:24:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.10.43.132:54404
17/12/17 15:24:38 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/17 15:24:38 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/17 15:24:38 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(0): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 44517, None)
uncompressedSizes(0): 4615537
uncompressedSizes(1): 4615537
uncompressedSizes(2): 4615537
uncompressedSizes(3): 4615537
uncompressedSizes(4): 4615537
uncompressedSizes(5): 4615537
uncompressedSizes(6): 4615537
uncompressedSizes(7): 4615537


17/12/17 15:24:38 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(1): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 36123, None)
uncompressedSizes(0): 4615537
uncompressedSizes(1): 4615537
uncompressedSizes(2): 4615537
uncompressedSizes(3): 4615537
uncompressedSizes(4): 4615537
uncompressedSizes(5): 4615537
uncompressedSizes(6): 4615537
uncompressedSizes(7): 4615537


17/12/17 15:24:38 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(2): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 44517, None)
uncompressedSizes(0): 4615537
uncompressedSizes(1): 4615537
uncompressedSizes(2): 4615537
uncompressedSizes(3): 4615537
uncompressedSizes(4): 4615537
uncompressedSizes(5): 4615537
uncompressedSizes(6): 4615537
uncompressedSizes(7): 4615537


17/12/17 15:24:38 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(3): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 36123, None)
uncompressedSizes(0): 4615537
uncompressedSizes(1): 4615537
uncompressedSizes(2): 4615537
uncompressedSizes(3): 4615537
uncompressedSizes(4): 4615537
uncompressedSizes(5): 4615537
uncompressedSizes(6): 4615537
uncompressedSizes(7): 4615537


17/12/17 15:24:38 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(4): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 44517, None)
uncompressedSizes(0): 4615537
uncompressedSizes(1): 4615537
uncompressedSizes(2): 4615537
uncompressedSizes(3): 4615537
uncompressedSizes(4): 4615537
uncompressedSizes(5): 4615537
uncompressedSizes(6): 4615537
uncompressedSizes(7): 4615537


17/12/17 15:24:38 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(5): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 36123, None)
uncompressedSizes(0): 4615537
uncompressedSizes(1): 4615537
uncompressedSizes(2): 4615537
uncompressedSizes(3): 4615537
uncompressedSizes(4): 4615537
uncompressedSizes(5): 4615537
uncompressedSizes(6): 4615537
uncompressedSizes(7): 4615537


17/12/17 15:24:38 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(6): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 44517, None)
uncompressedSizes(0): 4615537
uncompressedSizes(1): 4615537
uncompressedSizes(2): 4615537
uncompressedSizes(3): 4615537
uncompressedSizes(4): 4615537
uncompressedSizes(5): 4615537
uncompressedSizes(6): 4615537
uncompressedSizes(7): 4615537


17/12/17 15:24:38 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(7): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 36123, None)
uncompressedSizes(0): 4615537
uncompressedSizes(1): 4615537
uncompressedSizes(2): 4615537
uncompressedSizes(3): 4615537
uncompressedSizes(4): 4615537
uncompressedSizes(5): 4615537
uncompressedSizes(6): 4615537
uncompressedSizes(7): 4615537


17/12/17 15:24:38 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 164 bytes
17/12/17 15:24:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.10.43.131:44517 (size: 22.9 KB, free: 366.3 MB)
17/12/17 15:24:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.10.43.131:43908
17/12/17 15:24:38 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: [B@3f1217fb


17/12/17 15:24:42 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 13) in 4698 ms on 10.10.43.131 (executor 1) (1/8)
17/12/17 15:24:43 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 9) in 5246 ms on 10.10.43.131 (executor 1) (2/8)
17/12/17 15:24:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 8) in 5402 ms on 10.10.43.132 (executor 0) (3/8)
17/12/17 15:24:43 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 10) in 5663 ms on 10.10.43.132 (executor 0) (4/8)
17/12/17 15:24:43 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 12) in 5733 ms on 10.10.43.132 (executor 0) (5/8)
17/12/17 15:24:43 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 11) in 5760 ms on 10.10.43.131 (executor 1) (6/8)
17/12/17 15:24:43 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 14) in 5809 ms on 10.10.43.132 (executor 0) (7/8)
17/12/17 15:24:43 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 15) in 6146 ms on 10.10.43.131 (executor 1) (8/8)
17/12/17 15:24:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
17/12/17 15:24:43 INFO DAGScheduler: ResultStage 1 (saveAsHadoopFile at IOCommon.scala:63) finished in 6.154 s
17/12/17 15:24:43 INFO DAGScheduler: Job 0 finished: saveAsHadoopFile at IOCommon.scala:63, took 14.741895 s
17/12/17 15:24:44 INFO SparkUI: Stopped Spark web UI at http://10.10.43.130:4040
17/12/17 15:24:44 INFO StandaloneSchedulerBackend: Shutting down all executors
17/12/17 15:24:44 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
17/12/17 15:24:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/17 15:24:44 INFO MemoryStore: MemoryStore cleared
17/12/17 15:24:44 INFO BlockManager: BlockManager stopped
17/12/17 15:24:44 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/17 15:24:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/17 15:24:44 INFO SparkContext: Successfully stopped SparkContext
17/12/17 15:24:44 INFO ShutdownHookManager: Shutdown hook called
17/12/17 15:24:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-51b7894c-127e-42a8-8bf7-e6efc21c7ee4
