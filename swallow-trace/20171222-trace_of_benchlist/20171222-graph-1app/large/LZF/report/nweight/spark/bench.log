17/12/22 18:36:10 INFO SparkContext: Running Spark version 2.2.0
17/12/22 18:36:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/22 18:36:11 INFO SparkContext: Submitted application: NWeightGraphX
17/12/22 18:36:11 INFO SecurityManager: Changing view acls to: hadoop
17/12/22 18:36:11 INFO SecurityManager: Changing modify acls to: hadoop
17/12/22 18:36:11 INFO SecurityManager: Changing view acls groups to:
17/12/22 18:36:11 INFO SecurityManager: Changing modify acls groups to:
17/12/22 18:36:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
17/12/22 18:36:12 INFO Utils: Successfully started service 'sparkDriver' on port 35333.
compressShuffle => [spark.shuffle.compress : true]
17/12/22 18:36:12 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/22 18:36:12 INFO SparkEnv: Registering MapOutputTracker
17/12/22 18:36:12 INFO SparkEnv: Registering BlockManagerMaster
17/12/22 18:36:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/22 18:36:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/22 18:36:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9adda8d7-9e2b-4574-847e-7c9d8d45cda5
17/12/22 18:36:12 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
17/12/22 18:36:12 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/22 18:36:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/12/22 18:36:12 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/12/22 18:36:12 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.10.43.130:4041
17/12/22 18:36:12 INFO SparkContext: Added JAR file:/home/hadoop/hadoopTest/HiBench2-LZF/sparkbench/assembly/target/sparkbench-assembly-7.1-SNAPSHOT-dist.jar at spark://10.10.43.130:35333/jars/sparkbench-assembly-7.1-SNAPSHOT-dist.jar with timestamp 1513938972969
17/12/22 18:36:13 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://cluster209-hadoop-master:7077...
17/12/22 18:36:13 INFO TransportClientFactory: Successfully created connection to cluster209-hadoop-master/10.10.43.130:7077 after 32 ms (0 ms spent in bootstraps)
17/12/22 18:36:13 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20171222183613-0009
17/12/22 18:36:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37416.
17/12/22 18:36:13 INFO NettyBlockTransferService: Server created on 10.10.43.130:37416
17/12/22 18:36:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/22 18:36:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.10.43.130, 37416, None)
17/12/22 18:36:13 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.43.130:37416 with 912.3 MB RAM, BlockManagerId(driver, 10.10.43.130, 37416, None)
17/12/22 18:36:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.10.43.130, 37416, None)
17/12/22 18:36:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.10.43.130, 37416, None)
17/12/22 18:36:14 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/12/22 18:36:15 INFO SparkContext:
******************** [KMDebug] ********************
Init with textFile
17/12/22 18:36:16 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/22 18:36:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 219.1 KB, free 912.1 MB)
17/12/22 18:36:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 912.1 MB)
17/12/22 18:36:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.10.43.130:37416 (size: 20.6 KB, free: 912.3 MB)
17/12/22 18:36:17 INFO SparkContext: Created broadcast 0 from textFile at GraphxNWeight.scala:74
17/12/22 18:36:19 INFO SparkContext: Starting job: saveAsTextFile at GraphxNWeight.scala:112
17/12/22 18:36:19 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/22 18:36:20 INFO FileInputFormat: Total input paths to process : 8
17/12/22 18:36:20 INFO DAGScheduler: Registering RDD 2 (flatMap at GraphxNWeight.scala:74)
17/12/22 18:36:20 INFO DAGScheduler: Registering RDD 5 (map at GraphxNWeight.scala:85)
17/12/22 18:36:20 INFO DAGScheduler: Registering RDD 7 (map at GraphxNWeight.scala:87)
17/12/22 18:36:20 INFO DAGScheduler: Registering RDD 12 (mapPartitions at VertexRDD.scala:356)
17/12/22 18:36:20 INFO DAGScheduler: Registering RDD 20 (mapPartitions at VertexRDDImpl.scala:247)
17/12/22 18:36:20 INFO DAGScheduler: Registering RDD 24 (mapPartitions at GraphImpl.scala:207)
17/12/22 18:36:20 INFO DAGScheduler: Registering RDD 32 (mapPartitions at VertexRDDImpl.scala:247)
17/12/22 18:36:20 INFO DAGScheduler: Registering RDD 36 (mapPartitions at GraphImpl.scala:207)
17/12/22 18:36:20 INFO DAGScheduler: Got job 0 (saveAsTextFile at GraphxNWeight.scala:112) with 8 output partitions
17/12/22 18:36:20 INFO DAGScheduler: Final stage: ResultStage 8 (saveAsTextFile at GraphxNWeight.scala:112)
17/12/22 18:36:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 2, ShuffleMapStage 3, ShuffleMapStage 7)
17/12/22 18:36:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 2, ShuffleMapStage 3, ShuffleMapStage 7)
17/12/22 18:36:20 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at GraphxNWeight.scala:74), which has no missing parents
17/12/22 18:36:20 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/22 18:36:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.5 KB, free 912.1 MB)
17/12/22 18:36:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
17/12/22 18:36:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.10.43.130:37416 (size: 2.6 KB, free: 912.3 MB)
17/12/22 18:36:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
17/12/22 18:36:20 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at GraphxNWeight.scala:74) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
17/12/22 18:36:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 8 tasks
17/12/22 18:36:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:36:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:37:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:37:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:37:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:37:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:38:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:38:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:38:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:38:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:39:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:39:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:39:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:39:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:40:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:40:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:40:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:40:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:41:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:41:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:41:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:41:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:42:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:42:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:42:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:42:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:43:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/12/22 18:43:09 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20171222183613-0009/0 on worker-20171222154019-10.10.43.132-45268 (10.10.43.132:45268) with 4 cores
17/12/22 18:43:09 INFO StandaloneSchedulerBackend: Granted executor ID app-20171222183613-0009/0 on hostPort 10.10.43.132:45268 with 4 cores, 2.0 GB RAM
17/12/22 18:43:09 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20171222183613-0009/1 on worker-20171222154114-10.10.43.131-39436 (10.10.43.131:39436) with 4 cores
17/12/22 18:43:09 INFO StandaloneSchedulerBackend: Granted executor ID app-20171222183613-0009/1 on hostPort 10.10.43.131:39436 with 4 cores, 2.0 GB RAM
17/12/22 18:43:09 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171222183613-0009/0 is now RUNNING
17/12/22 18:43:09 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171222183613-0009/1 is now RUNNING
17/12/22 18:43:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.43.132:43236) with ID 0
17/12/22 18:43:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 10.10.43.132, executor 0, partition 0, ANY, 4906 bytes)
17/12/22 18:43:13 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 10.10.43.132, executor 0, partition 1, ANY, 4906 bytes)
17/12/22 18:43:13 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 10.10.43.132, executor 0, partition 2, ANY, 4906 bytes)
17/12/22 18:43:13 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 10.10.43.132, executor 0, partition 3, ANY, 4906 bytes)
17/12/22 18:43:13 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.43.132:41411 with 912.3 MB RAM, BlockManagerId(0, 10.10.43.132, 41411, None)
17/12/22 18:43:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.43.131:60788) with ID 1
17/12/22 18:43:13 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 10.10.43.131, executor 1, partition 4, ANY, 4906 bytes)
17/12/22 18:43:13 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 10.10.43.131, executor 1, partition 5, ANY, 4906 bytes)
17/12/22 18:43:13 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 10.10.43.131, executor 1, partition 6, ANY, 4906 bytes)
17/12/22 18:43:13 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 10.10.43.131, executor 1, partition 7, ANY, 4906 bytes)
17/12/22 18:43:13 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.43.131:37959 with 912.3 MB RAM, BlockManagerId(1, 10.10.43.131, 37959, None)
17/12/22 18:43:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.10.43.132:41411 (size: 2.6 KB, free: 912.3 MB)
17/12/22 18:43:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.10.43.132:41411 (size: 20.6 KB, free: 912.3 MB)
17/12/22 18:43:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.10.43.131:37959 (size: 2.6 KB, free: 912.3 MB)
17/12/22 18:43:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.10.43.131:37959 (size: 20.6 KB, free: 912.3 MB)
17/12/22 18:43:32 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 18618 ms on 10.10.43.131 (executor 1) (1/8)
17/12/22 18:43:32 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 19675 ms on 10.10.43.132 (executor 0) (2/8)
17/12/22 18:43:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 19822 ms on 10.10.43.132 (executor 0) (3/8)
17/12/22 18:43:33 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 19337 ms on 10.10.43.131 (executor 1) (4/8)
17/12/22 18:43:33 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 20466 ms on 10.10.43.132 (executor 0) (5/8)
17/12/22 18:43:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 21136 ms on 10.10.43.132 (executor 0) (6/8)
17/12/22 18:43:35 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 21962 ms on 10.10.43.131 (executor 1) (7/8)
17/12/22 18:43:36 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 22511 ms on 10.10.43.131 (executor 1) (8/8)
17/12/22 18:43:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
17/12/22 18:43:36 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at GraphxNWeight.scala:74) finished in 435.409 s
17/12/22 18:43:36 INFO DAGScheduler: looking for newly runnable stages
17/12/22 18:43:36 INFO DAGScheduler: running: Set()
17/12/22 18:43:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ShuffleMapStage 5, ShuffleMapStage 2, ShuffleMapStage 6, ShuffleMapStage 3, ShuffleMapStage 7, ShuffleMapStage 4, ResultStage 8)
17/12/22 18:43:36 INFO DAGScheduler: failed: Set()
17/12/22 18:43:36 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at map at GraphxNWeight.scala:85), which has no missing parents
17/12/22 18:43:36 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/22 18:43:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.4 KB, free 912.1 MB)
17/12/22 18:43:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KB, free 912.1 MB)
17/12/22 18:43:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.10.43.130:37416 (size: 2.3 KB, free: 912.3 MB)
17/12/22 18:43:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/12/22 18:43:36 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at map at GraphxNWeight.scala:85) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
17/12/22 18:43:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 8 tasks
17/12/22 18:43:36 INFO DAGScheduler: Submitting ShuffleMapStage 3 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[12] at mapPartitions at VertexRDD.scala:356), which has no missing parents
17/12/22 18:43:36 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 8, 10.10.43.131, executor 1, partition 4, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 9, 10.10.43.132, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:36 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 10, 10.10.43.131, executor 1, partition 5, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 11, 10.10.43.132, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:36 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 12, 10.10.43.131, executor 1, partition 6, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:36 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 13, 10.10.43.132, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:36 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 14, 10.10.43.131, executor 1, partition 7, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:36 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 15, 10.10.43.132, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:36 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/22 18:43:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.1 KB, free 912.0 MB)
17/12/22 18:43:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.3 KB, free 912.0 MB)
17/12/22 18:43:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.10.43.130:37416 (size: 2.3 KB, free: 912.3 MB)
17/12/22 18:43:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
17/12/22 18:43:36 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 3 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[12] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
17/12/22 18:43:36 INFO TaskSchedulerImpl: Adding task set 3.0 with 8 tasks
17/12/22 18:43:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.10.43.132:41411 (size: 2.3 KB, free: 912.3 MB)
17/12/22 18:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.10.43.132:43236
17/12/22 18:43:36 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/22 18:43:36 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/22 18:43:36 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(0): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 31051030
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:43:36 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(1): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 31051030
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:43:36 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(2): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 31051030
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:43:36 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(3): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 31051030
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:43:36 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(4): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 31051030
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:43:36 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(5): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 31051030
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:43:36 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(6): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 31051030
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:43:36 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(7): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 31051030
totalSize: 31051030


17/12/22 18:43:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 191 bytes
17/12/22 18:43:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.10.43.131:37959 (size: 2.3 KB, free: 912.3 MB)
17/12/22 18:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.10.43.131:60788
17/12/22 18:43:37 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: [B@242e6fb4


17/12/22 18:43:44 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 16, 10.10.43.132, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 11) in 8576 ms on 10.10.43.132 (executor 0) (1/8)
17/12/22 18:43:45 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.10.43.132:41411 (size: 2.3 KB, free: 912.3 MB)
17/12/22 18:43:45 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 17, 10.10.43.132, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 9) in 8915 ms on 10.10.43.132 (executor 0) (2/8)
17/12/22 18:43:46 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 18, 10.10.43.132, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:46 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 13) in 9718 ms on 10.10.43.132 (executor 0) (3/8)
17/12/22 18:43:46 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 19, 10.10.43.132, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:46 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 15) in 10657 ms on 10.10.43.132 (executor 0) (4/8)
17/12/22 18:43:48 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 20, 10.10.43.131, executor 1, partition 4, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:48 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 10) in 12155 ms on 10.10.43.131 (executor 1) (5/8)
17/12/22 18:43:48 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 21, 10.10.43.131, executor 1, partition 5, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:48 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 14) in 12350 ms on 10.10.43.131 (executor 1) (6/8)
17/12/22 18:43:48 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 22, 10.10.43.131, executor 1, partition 6, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:48 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 12) in 12482 ms on 10.10.43.131 (executor 1) (7/8)
17/12/22 18:43:48 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 23, 10.10.43.131, executor 1, partition 7, NODE_LOCAL, 4614 bytes)
17/12/22 18:43:48 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 8) in 12618 ms on 10.10.43.131 (executor 1) (8/8)
17/12/22 18:43:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
17/12/22 18:43:48 INFO DAGScheduler: ShuffleMapStage 1 (map at GraphxNWeight.scala:85) finished in 12.619 s
17/12/22 18:43:48 INFO DAGScheduler: looking for newly runnable stages
17/12/22 18:43:48 INFO DAGScheduler: running: Set(ShuffleMapStage 3)
17/12/22 18:43:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 2, ShuffleMapStage 6, ShuffleMapStage 7, ShuffleMapStage 4, ResultStage 8)
17/12/22 18:43:48 INFO DAGScheduler: failed: Set()
17/12/22 18:43:48 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at map at GraphxNWeight.scala:87), which has no missing parents
17/12/22 18:43:48 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/22 18:43:48 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 5.0 KB, free 912.0 MB)
17/12/22 18:43:48 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.0 MB)
17/12/22 18:43:48 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.10.43.130:37416 (size: 2.6 KB, free: 912.3 MB)
17/12/22 18:43:48 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
17/12/22 18:43:48 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at map at GraphxNWeight.scala:87) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
17/12/22 18:43:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 8 tasks
17/12/22 18:43:49 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.10.43.131:37959 (size: 2.3 KB, free: 912.3 MB)
17/12/22 18:44:18 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 24, 10.10.43.131, executor 1, partition 4, NODE_LOCAL, 4614 bytes)
17/12/22 18:44:18 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 21) in 30257 ms on 10.10.43.131 (executor 1) (1/8)
17/12/22 18:44:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 25, 10.10.43.132, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
17/12/22 18:44:18 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 16) in 34049 ms on 10.10.43.132 (executor 0) (2/8)
17/12/22 18:44:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.10.43.131:37959 (size: 2.6 KB, free: 912.3 MB)
17/12/22 18:44:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.10.43.131:60788
17/12/22 18:44:18 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/22 18:44:18 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/22 18:44:18 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(0): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 31051030
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:18 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(1): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 31051030
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:18 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(2): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 31051030
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:18 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(3): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 31051030
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:18 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(4): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 31051030
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:18 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(5): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 31051030
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:18 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(6): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 31051030
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:18 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(7): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 31051030
totalSize: 31051030


17/12/22 18:44:18 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 191 bytes
17/12/22 18:44:19 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.10.43.132:41411 (size: 2.6 KB, free: 912.3 MB)
17/12/22 18:44:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 26, 10.10.43.132, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
17/12/22 18:44:19 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 17) in 33895 ms on 10.10.43.132 (executor 0) (3/8)
17/12/22 18:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.10.43.132:43236
17/12/22 18:44:19 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: [B@1a38d5b2


17/12/22 18:44:19 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 27, 10.10.43.132, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
17/12/22 18:44:19 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 19) in 32435 ms on 10.10.43.132 (executor 0) (4/8)
17/12/22 18:44:19 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 28, 10.10.43.132, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
17/12/22 18:44:19 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 18) in 33468 ms on 10.10.43.132 (executor 0) (5/8)
17/12/22 18:44:19 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 29, 10.10.43.131, executor 1, partition 5, NODE_LOCAL, 4614 bytes)
17/12/22 18:44:19 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 20) in 31162 ms on 10.10.43.131 (executor 1) (6/8)
17/12/22 18:44:19 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 30, 10.10.43.131, executor 1, partition 6, NODE_LOCAL, 4614 bytes)
17/12/22 18:44:19 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 22) in 30841 ms on 10.10.43.131 (executor 1) (7/8)
17/12/22 18:44:19 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 31, 10.10.43.131, executor 1, partition 7, NODE_LOCAL, 4614 bytes)
17/12/22 18:44:19 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 23) in 30767 ms on 10.10.43.131 (executor 1) (8/8)
17/12/22 18:44:19 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
17/12/22 18:44:19 INFO DAGScheduler: ShuffleMapStage 3 (mapPartitions at VertexRDD.scala:356) finished in 43.333 s
17/12/22 18:44:19 INFO DAGScheduler: looking for newly runnable stages
17/12/22 18:44:19 INFO DAGScheduler: running: Set(ShuffleMapStage 2)
17/12/22 18:44:19 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 6, ShuffleMapStage 7, ShuffleMapStage 4, ResultStage 8)
17/12/22 18:44:19 INFO DAGScheduler: failed: Set()
17/12/22 18:44:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 25) in 12830 ms on 10.10.43.132 (executor 0) (1/8)
17/12/22 18:44:31 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 27) in 12617 ms on 10.10.43.132 (executor 0) (2/8)
17/12/22 18:44:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 26) in 12964 ms on 10.10.43.132 (executor 0) (3/8)
17/12/22 18:44:32 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 28) in 12964 ms on 10.10.43.132 (executor 0) (4/8)
17/12/22 18:44:33 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 24) in 14898 ms on 10.10.43.131 (executor 1) (5/8)
17/12/22 18:44:33 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 30) in 14196 ms on 10.10.43.131 (executor 1) (6/8)
17/12/22 18:44:33 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 31) in 14224 ms on 10.10.43.131 (executor 1) (7/8)
17/12/22 18:44:33 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 29) in 14324 ms on 10.10.43.131 (executor 1) (8/8)
17/12/22 18:44:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
17/12/22 18:44:33 INFO DAGScheduler: ShuffleMapStage 2 (map at GraphxNWeight.scala:87) finished in 45.005 s
17/12/22 18:44:33 INFO DAGScheduler: looking for newly runnable stages
17/12/22 18:44:33 INFO DAGScheduler: running: Set()
17/12/22 18:44:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 6, ShuffleMapStage 7, ShuffleMapStage 4, ResultStage 8)
17/12/22 18:44:33 INFO DAGScheduler: failed: Set()
17/12/22 18:44:33 INFO DAGScheduler: Submitting ShuffleMapStage 4 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[20] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
17/12/22 18:44:33 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/22 18:44:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.1 KB, free 912.0 MB)
17/12/22 18:44:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.0 MB)
17/12/22 18:44:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.10.43.130:37416 (size: 2.8 KB, free: 912.3 MB)
17/12/22 18:44:33 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
17/12/22 18:44:33 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 4 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[20] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
17/12/22 18:44:33 INFO TaskSchedulerImpl: Adding task set 4.0 with 8 tasks
17/12/22 18:44:33 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 32, 10.10.43.131, executor 1, partition 4, NODE_LOCAL, 4934 bytes)
17/12/22 18:44:33 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 33, 10.10.43.132, executor 0, partition 0, NODE_LOCAL, 4934 bytes)
17/12/22 18:44:33 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 34, 10.10.43.131, executor 1, partition 5, NODE_LOCAL, 4934 bytes)
17/12/22 18:44:33 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 35, 10.10.43.132, executor 0, partition 1, NODE_LOCAL, 4934 bytes)
17/12/22 18:44:33 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 36, 10.10.43.131, executor 1, partition 6, NODE_LOCAL, 4934 bytes)
17/12/22 18:44:33 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 37, 10.10.43.132, executor 0, partition 2, NODE_LOCAL, 4934 bytes)
17/12/22 18:44:33 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 38, 10.10.43.131, executor 1, partition 7, NODE_LOCAL, 4934 bytes)
17/12/22 18:44:33 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 39, 10.10.43.132, executor 0, partition 3, NODE_LOCAL, 4934 bytes)
17/12/22 18:44:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.10.43.132:41411 (size: 2.8 KB, free: 912.3 MB)
17/12/22 18:44:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.10.43.132:43236
17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(0): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 31051030
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(1): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 31051030
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(2): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 31051030
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(3): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 31051030
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(4): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 31051030
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(5): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 31051030
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(6): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 31051030
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(7): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 31051030
totalSize: 31051030


17/12/22 18:44:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 191 bytes
17/12/22 18:44:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.10.43.132:43236
17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(0): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 1957438
uncompressedSizes(1): 1104923
uncompressedSizes(2): 1104923
uncompressedSizes(3): 1104923
uncompressedSizes(4): 1104923
uncompressedSizes(5): 1104923
uncompressedSizes(6): 1104923
uncompressedSizes(7): 1104923
totalSize: 9691899


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(1): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 1104923
uncompressedSizes(1): 1779489
uncompressedSizes(2): 1104923
uncompressedSizes(3): 1104923
uncompressedSizes(4): 1104923
uncompressedSizes(5): 1104923
uncompressedSizes(6): 1104923
uncompressedSizes(7): 1104923
totalSize: 9513950


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(2): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 1104923
uncompressedSizes(1): 1104923
uncompressedSizes(2): 1779489
uncompressedSizes(3): 1104923
uncompressedSizes(4): 1104923
uncompressedSizes(5): 1104923
uncompressedSizes(6): 1104923
uncompressedSizes(7): 1104923
totalSize: 9513950


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(3): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 1104923
uncompressedSizes(1): 1104923
uncompressedSizes(2): 1104923
uncompressedSizes(3): 1779489
uncompressedSizes(4): 1104923
uncompressedSizes(5): 1104923
uncompressedSizes(6): 1104923
uncompressedSizes(7): 1104923
totalSize: 9513950


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(4): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 1104923
uncompressedSizes(1): 1104923
uncompressedSizes(2): 1104923
uncompressedSizes(3): 1104923
uncompressedSizes(4): 1779489
uncompressedSizes(5): 1104923
uncompressedSizes(6): 1104923
uncompressedSizes(7): 1104923
totalSize: 9513950


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(5): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 1104923
uncompressedSizes(1): 1104923
uncompressedSizes(2): 1104923
uncompressedSizes(3): 1104923
uncompressedSizes(4): 1104923
uncompressedSizes(5): 1779489
uncompressedSizes(6): 1104923
uncompressedSizes(7): 1104923
totalSize: 9513950


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(6): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 1104923
uncompressedSizes(1): 1104923
uncompressedSizes(2): 1104923
uncompressedSizes(3): 1104923
uncompressedSizes(4): 1104923
uncompressedSizes(5): 1104923
uncompressedSizes(6): 1779489
uncompressedSizes(7): 1104923
totalSize: 9513950


17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(7): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 37959, None)
uncompressedSizes(0): 1104923
uncompressedSizes(1): 1104923
uncompressedSizes(2): 1104923
uncompressedSizes(3): 1104923
uncompressedSizes(4): 1104923
uncompressedSizes(5): 1104923
uncompressedSizes(6): 1104923
uncompressedSizes(7): 1779489
totalSize: 9513950


17/12/22 18:44:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 192 bytes
17/12/22 18:44:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.10.43.131:37959 (size: 2.8 KB, free: 912.3 MB)
17/12/22 18:44:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.10.43.131:60788
17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: [B@60c17efd


17/12/22 18:44:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.10.43.131:60788
17/12/22 18:44:34 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: [B@1d1afd1


17/12/22 18:44:43 INFO BlockManagerInfo: Added rdd_15_1 in memory on 10.10.43.132:41411 (size: 141.1 MB, free: 771.2 MB)
17/12/22 18:44:44 INFO BlockManagerInfo: Added rdd_15_2 in memory on 10.10.43.132:41411 (size: 152.5 MB, free: 618.7 MB)
17/12/22 18:44:45 INFO BlockManagerInfo: Added rdd_15_0 in memory on 10.10.43.132:41411 (size: 158.7 MB, free: 460.0 MB)
17/12/22 18:44:45 INFO BlockManagerInfo: Added rdd_15_5 in memory on 10.10.43.131:37959 (size: 158.5 MB, free: 753.7 MB)
17/12/22 18:44:45 INFO BlockManagerInfo: Added rdd_15_6 in memory on 10.10.43.131:37959 (size: 184.6 MB, free: 569.2 MB)
17/12/22 18:44:45 INFO BlockManagerInfo: Added rdd_15_4 in memory on 10.10.43.131:37959 (size: 162.5 MB, free: 406.7 MB)
17/12/22 18:44:46 INFO BlockManagerInfo: Added rdd_15_3 in memory on 10.10.43.132:41411 (size: 175.8 MB, free: 284.1 MB)
17/12/22 18:44:46 INFO BlockManagerInfo: Added rdd_15_7 in memory on 10.10.43.131:37959 (size: 171.8 MB, free: 234.8 MB)
17/12/22 18:45:40 WARN TaskSetManager: Lost task 2.0 in stage 4.0 (TID 37, 10.10.43.132, executor 0): java.lang.ArrayIndexOutOfBoundsException: 4194303
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65)
	at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:209)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:239)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

17/12/22 18:45:40 INFO TaskSetManager: Starting task 2.1 in stage 4.0 (TID 40, 10.10.43.132, executor 0, partition 2, NODE_LOCAL, 4934 bytes)
17/12/22 18:45:49 WARN TaskSetManager: Lost task 7.0 in stage 4.0 (TID 38, 10.10.43.131, executor 1): java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:448)
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:117)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41)
	at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:658)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:623)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:209)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:239)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

17/12/22 18:45:49 INFO TaskSetManager: Starting task 7.1 in stage 4.0 (TID 41, 10.10.43.131, executor 1, partition 7, NODE_LOCAL, 4934 bytes)
17/12/22 18:45:50 ERROR TaskSchedulerImpl: Lost executor 1 on 10.10.43.131: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/22 18:45:50 WARN TaskSetManager: Lost task 7.1 in stage 4.0 (TID 41, 10.10.43.131, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/22 18:45:50 WARN TaskSetManager: Lost task 4.0 in stage 4.0 (TID 32, 10.10.43.131, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/22 18:45:50 WARN TaskSetManager: Lost task 5.0 in stage 4.0 (TID 34, 10.10.43.131, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/22 18:45:50 WARN TaskSetManager: Lost task 6.0 in stage 4.0 (TID 36, 10.10.43.131, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/22 18:45:50 INFO DAGScheduler: Executor lost: 1 (epoch 4)
17/12/22 18:45:50 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
17/12/22 18:45:50 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_15_7 !
17/12/22 18:45:50 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_15_6 !
17/12/22 18:45:50 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_15_5 !
17/12/22 18:45:50 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_15_4 !
17/12/22 18:45:50 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 10.10.43.131, 37959, None)
17/12/22 18:45:50 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor
17/12/22 18:45:50 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171222183613-0009/1 is now EXITED (Command exited with code 52)
17/12/22 18:45:50 INFO DAGScheduler: Shuffle files lost for executor: 1 (epoch 4)
17/12/22 18:45:50 INFO StandaloneSchedulerBackend: Executor app-20171222183613-0009/1 removed: Command exited with code 52
17/12/22 18:45:50 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20171222183613-0009/2 on worker-20171222154114-10.10.43.131-39436 (10.10.43.131:39436) with 4 cores
17/12/22 18:45:50 INFO StandaloneSchedulerBackend: Granted executor ID app-20171222183613-0009/2 on hostPort 10.10.43.131:39436 with 4 cores, 2.0 GB RAM
17/12/22 18:45:50 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
17/12/22 18:45:50 INFO BlockManagerMaster: Removal of executor 1 requested
17/12/22 18:45:50 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 1 (4/8, false)
17/12/22 18:45:50 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 1
17/12/22 18:45:50 INFO ShuffleMapStage: ShuffleMapStage 1 is now unavailable on executor 1 (4/8, false)
17/12/22 18:45:50 INFO ShuffleMapStage: ShuffleMapStage 2 is now unavailable on executor 1 (4/8, false)
17/12/22 18:45:50 INFO ShuffleMapStage: ShuffleMapStage 3 is now unavailable on executor 1 (4/8, false)
17/12/22 18:45:50 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171222183613-0009/2 is now RUNNING
17/12/22 18:45:53 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.43.131:60810) with ID 2
17/12/22 18:45:53 INFO TaskSetManager: Starting task 6.1 in stage 4.0 (TID 42, 10.10.43.131, executor 2, partition 6, NODE_LOCAL, 4934 bytes)
17/12/22 18:45:53 INFO TaskSetManager: Starting task 5.1 in stage 4.0 (TID 43, 10.10.43.131, executor 2, partition 5, NODE_LOCAL, 4934 bytes)
17/12/22 18:45:53 INFO TaskSetManager: Starting task 4.1 in stage 4.0 (TID 44, 10.10.43.131, executor 2, partition 4, NODE_LOCAL, 4934 bytes)
17/12/22 18:45:53 INFO TaskSetManager: Starting task 7.2 in stage 4.0 (TID 45, 10.10.43.131, executor 2, partition 7, NODE_LOCAL, 4934 bytes)
17/12/22 18:45:53 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.43.131:34823 with 912.3 MB RAM, BlockManagerId(2, 10.10.43.131, 34823, None)
17/12/22 18:45:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.10.43.131:34823 (size: 2.8 KB, free: 912.3 MB)
17/12/22 18:45:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.10.43.131:60810
17/12/22 18:45:56 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/22 18:45:56 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/22 18:45:56 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(0): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 31051030
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:45:56 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(1): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 31051030
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:45:56 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(2): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 31051030
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:45:56 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(3): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 41411, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 31051030
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 31051030


17/12/22 18:45:56 ERROR MapOutputTrackerMaster:
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$getSerializedMapOutputStatuses$1.apply$mcVI$sp(MapOutputTracker.scala:573)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:570)
	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:352)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/12/22 18:46:11 WARN TaskSetManager: Lost task 3.0 in stage 4.0 (TID 39, 10.10.43.132, executor 0): java.lang.OutOfMemoryError: Java heap space
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:448)
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:220)
	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41)
	at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:658)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:623)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628)
	at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:209)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:239)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

17/12/22 18:46:11 INFO TaskSetManager: Starting task 3.1 in stage 4.0 (TID 46, 10.10.43.132, executor 0, partition 3, NODE_LOCAL, 4934 bytes)
17/12/22 18:46:12 ERROR TaskSchedulerImpl: Lost executor 0 on 10.10.43.132: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/22 18:46:12 WARN TaskSetManager: Lost task 1.0 in stage 4.0 (TID 35, 10.10.43.132, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/22 18:46:12 WARN TaskSetManager: Lost task 3.1 in stage 4.0 (TID 46, 10.10.43.132, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/22 18:46:12 WARN TaskSetManager: Lost task 2.1 in stage 4.0 (TID 40, 10.10.43.132, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/22 18:46:12 WARN TaskSetManager: Lost task 0.0 in stage 4.0 (TID 33, 10.10.43.132, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/22 18:46:12 INFO DAGScheduler: Executor lost: 0 (epoch 12)
17/12/22 18:46:12 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
17/12/22 18:46:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_15_1 !
17/12/22 18:46:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_15_0 !
17/12/22 18:46:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_15_3 !
17/12/22 18:46:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_15_2 !
17/12/22 18:46:12 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 10.10.43.132, 41411, None)
17/12/22 18:46:12 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor
17/12/22 18:46:12 INFO DAGScheduler: Shuffle files lost for executor: 0 (epoch 12)
17/12/22 18:46:12 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 0 (0/8, false)
17/12/22 18:46:12 INFO ShuffleMapStage: ShuffleMapStage 1 is now unavailable on executor 0 (0/8, false)
17/12/22 18:46:12 INFO ShuffleMapStage: ShuffleMapStage 2 is now unavailable on executor 0 (0/8, false)
17/12/22 18:46:12 INFO ShuffleMapStage: ShuffleMapStage 3 is now unavailable on executor 0 (0/8, false)
17/12/22 18:46:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171222183613-0009/0 is now EXITED (Command exited with code 52)
17/12/22 18:46:12 INFO StandaloneSchedulerBackend: Executor app-20171222183613-0009/0 removed: Command exited with code 52
17/12/22 18:46:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20171222183613-0009/3 on worker-20171222154019-10.10.43.132-45268 (10.10.43.132:45268) with 4 cores
17/12/22 18:46:12 INFO BlockManagerMaster: Removal of executor 0 requested
17/12/22 18:46:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 0
17/12/22 18:46:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20171222183613-0009/3 on hostPort 10.10.43.132:45268 with 4 cores, 2.0 GB RAM
17/12/22 18:46:12 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
17/12/22 18:46:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171222183613-0009/3 is now RUNNING
17/12/22 18:46:14 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.43.132:43258) with ID 3
17/12/22 18:46:14 INFO TaskSetManager: Starting task 0.1 in stage 4.0 (TID 47, 10.10.43.132, executor 3, partition 0, NODE_LOCAL, 4934 bytes)
17/12/22 18:46:14 INFO TaskSetManager: Starting task 2.2 in stage 4.0 (TID 48, 10.10.43.132, executor 3, partition 2, NODE_LOCAL, 4934 bytes)
17/12/22 18:46:14 INFO TaskSetManager: Starting task 3.2 in stage 4.0 (TID 49, 10.10.43.132, executor 3, partition 3, NODE_LOCAL, 4934 bytes)
17/12/22 18:46:14 INFO TaskSetManager: Starting task 1.1 in stage 4.0 (TID 50, 10.10.43.132, executor 3, partition 1, NODE_LOCAL, 4934 bytes)
17/12/22 18:46:14 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.43.132:41027 with 912.3 MB RAM, BlockManagerId(3, 10.10.43.132, 41027, None)
17/12/22 18:46:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.10.43.132:41027 (size: 2.8 KB, free: 912.3 MB)
17/12/22 18:46:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.10.43.132:43258
17/12/22 18:46:16 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/22 18:46:16 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/22 18:46:16 ERROR MapOutputTrackerMaster:
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$getSerializedMapOutputStatuses$1.apply$mcVI$sp(MapOutputTracker.scala:573)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:570)
	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:352)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/12/22 18:47:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.10.43.131:60810
17/12/22 18:47:56 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/22 18:47:56 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/22 18:47:56 ERROR MapOutputTrackerMaster:
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$getSerializedMapOutputStatuses$1.apply$mcVI$sp(MapOutputTracker.scala:573)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:570)
	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:352)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/12/22 18:47:56 WARN TaskSetManager: Lost task 4.1 in stage 4.0 (TID 44, 10.10.43.131, executor 2): org.apache.spark.SparkException: Error communicating with MapOutputTracker
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:107)
	at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:205)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:145)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:334)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1039)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:970)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:761)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:76)
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:103)
	... 27 more
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 30 more

17/12/22 18:47:57 INFO TaskSetManager: Starting task 4.2 in stage 4.0 (TID 51, 10.10.43.131, executor 2, partition 4, NODE_LOCAL, 4934 bytes)
17/12/22 18:48:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.10.43.132:43258
17/12/22 18:48:16 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/22 18:48:16 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/22 18:48:16 ERROR MapOutputTrackerMaster:
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$getSerializedMapOutputStatuses$1.apply$mcVI$sp(MapOutputTracker.scala:573)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:570)
	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:352)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/12/22 18:48:16 WARN TaskSetManager: Lost task 2.2 in stage 4.0 (TID 48, 10.10.43.132, executor 3): org.apache.spark.SparkException: Error communicating with MapOutputTracker
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:107)
	at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:205)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:145)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:334)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1039)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:970)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:761)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:76)
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:103)
	... 27 more
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 30 more

17/12/22 18:48:16 INFO TaskSetManager: Starting task 2.3 in stage 4.0 (TID 52, 10.10.43.132, executor 3, partition 2, NODE_LOCAL, 4934 bytes)
17/12/22 18:48:45 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.10.43.130:37416 in memory (size: 2.3 KB, free: 912.3 MB)
17/12/22 18:48:45 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.10.43.130:37416 in memory (size: 2.3 KB, free: 912.3 MB)
17/12/22 18:48:45 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.10.43.130:37416 in memory (size: 2.6 KB, free: 912.3 MB)
17/12/22 18:49:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.10.43.131:60810
17/12/22 18:49:56 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/22 18:49:56 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/22 18:49:56 ERROR MapOutputTrackerMaster:
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$getSerializedMapOutputStatuses$1.apply$mcVI$sp(MapOutputTracker.scala:573)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:570)
	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:352)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/12/22 18:49:56 WARN TaskSetManager: Lost task 7.2 in stage 4.0 (TID 45, 10.10.43.131, executor 2): org.apache.spark.SparkException: Error communicating with MapOutputTracker
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:107)
	at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:205)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:145)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:334)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1039)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:970)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:761)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:76)
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:103)
	... 27 more
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 30 more

17/12/22 18:49:56 INFO TaskSetManager: Starting task 7.3 in stage 4.0 (TID 53, 10.10.43.131, executor 2, partition 7, NODE_LOCAL, 4934 bytes)
17/12/22 18:50:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.10.43.132:43258
17/12/22 18:50:16 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/22 18:50:16 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/22 18:50:16 ERROR MapOutputTrackerMaster:
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$getSerializedMapOutputStatuses$1.apply$mcVI$sp(MapOutputTracker.scala:573)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:570)
	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:352)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/12/22 18:50:16 WARN TaskSetManager: Lost task 1.1 in stage 4.0 (TID 50, 10.10.43.132, executor 3): org.apache.spark.SparkException: Error communicating with MapOutputTracker
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:107)
	at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:205)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:145)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:334)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1039)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:970)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:761)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from 10.10.43.130:35333 in 120 seconds. This timeout is controlled by spark.rpc.askTimeout
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:216)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Failure.recover(Try.scala:216)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:78)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:54)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:601)
	at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:106)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:599)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:153)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:205)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:239)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from 10.10.43.130:35333 in 120 seconds
	... 8 more

17/12/22 18:50:16 INFO TaskSetManager: Starting task 1.2 in stage 4.0 (TID 54, 10.10.43.132, executor 3, partition 1, NODE_LOCAL, 4934 bytes)
17/12/22 18:51:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.10.43.131:60810
17/12/22 18:51:56 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/22 18:51:56 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/22 18:51:56 ERROR MapOutputTrackerMaster:
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$getSerializedMapOutputStatuses$1.apply$mcVI$sp(MapOutputTracker.scala:573)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:570)
	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:352)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/12/22 18:51:56 WARN TaskSetManager: Lost task 4.2 in stage 4.0 (TID 51, 10.10.43.131, executor 2): org.apache.spark.SparkException: Error communicating with MapOutputTracker
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:107)
	at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:205)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:145)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:334)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1039)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:970)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:761)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:76)
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:103)
	... 27 more
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 30 more

17/12/22 18:51:56 INFO TaskSetManager: Starting task 4.3 in stage 4.0 (TID 55, 10.10.43.131, executor 2, partition 4, NODE_LOCAL, 4934 bytes)
17/12/22 18:52:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.10.43.132:43258
17/12/22 18:52:16 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/22 18:52:16 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/22 18:52:16 ERROR MapOutputTrackerMaster:
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$getSerializedMapOutputStatuses$1.apply$mcVI$sp(MapOutputTracker.scala:573)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:570)
	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:352)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/12/22 18:52:16 WARN TaskSetManager: Lost task 2.3 in stage 4.0 (TID 52, 10.10.43.132, executor 3): org.apache.spark.SparkException: Error communicating with MapOutputTracker
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:107)
	at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:205)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:145)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:334)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1039)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:970)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:761)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:76)
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:103)
	... 27 more
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 30 more

17/12/22 18:52:16 ERROR TaskSetManager: Task 2 in stage 4.0 failed 4 times; aborting job
17/12/22 18:52:16 INFO TaskSchedulerImpl: Cancelling stage 4
17/12/22 18:52:16 INFO TaskSchedulerImpl: Stage 4 was cancelled
17/12/22 18:52:16 INFO DAGScheduler: ShuffleMapStage 4 (mapPartitions at VertexRDDImpl.scala:247) failed in 462.627 s due to Job aborted due to stage failure: Task 2 in stage 4.0 failed 4 times, most recent failure: Lost task 2.3 in stage 4.0 (TID 52, 10.10.43.132, executor 3): org.apache.spark.SparkException: Error communicating with MapOutputTracker
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:107)
	at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:205)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:145)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:334)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1039)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:970)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:761)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:76)
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:103)
	... 27 more
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 30 more

Driver stacktrace:
17/12/22 18:52:16 INFO DAGScheduler: Job 0 failed: saveAsTextFile at GraphxNWeight.scala:112, took 956.828041 s
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 4.0 failed 4 times, most recent failure: Lost task 2.3 in stage 4.0 (TID 52, 10.10.43.132, executor 3): org.apache.spark.SparkException: Error communicating with MapOutputTracker
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:107)
	at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:205)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:145)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:334)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1039)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:970)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:761)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:76)
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:103)
	... 27 more
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 30 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2025)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2046)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2078)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1151)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1096)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1096)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1096)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1070)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1035)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:961)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:961)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:961)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:960)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1489)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1468)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1468)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1468)
	at com.intel.hibench.sparkbench.graph.nweight.GraphxNWeight$.nweight(GraphxNWeight.scala:112)
	at com.intel.hibench.sparkbench.graph.nweight.NWeight$.main(Driver.scala:87)
	at com.intel.hibench.sparkbench.graph.nweight.NWeight.main(Driver.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: org.apache.spark.SparkException: Error communicating with MapOutputTracker
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:107)
	at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:205)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:145)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:336)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:334)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1039)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:970)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1030)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:761)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:76)
	at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:103)
	... 27 more
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 30 more
17/12/22 18:52:16 INFO SparkContext: Invoking stop() from shutdown hook
17/12/22 18:52:16 INFO SparkUI: Stopped Spark web UI at http://10.10.43.130:4041
17/12/22 18:52:16 INFO StandaloneSchedulerBackend: Shutting down all executors
17/12/22 18:52:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
17/12/22 18:52:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/12/22 18:52:16 INFO MemoryStore: MemoryStore cleared
17/12/22 18:52:16 INFO BlockManager: BlockManager stopped
17/12/22 18:52:16 INFO BlockManagerMaster: BlockManagerMaster stopped
17/12/22 18:52:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/12/22 18:52:16 INFO SparkContext: Successfully stopped SparkContext
17/12/22 18:52:16 INFO ShutdownHookManager: Shutdown hook called
17/12/22 18:52:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-17fdad11-1f3c-48b7-ac5f-ad530d419082
