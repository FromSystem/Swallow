17/12/20 17:12:52 INFO SparkContext: Running Spark version 2.2.0
17/12/20 17:12:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/12/20 17:12:53 INFO SparkContext: Submitted application: NWeightGraphX
17/12/20 17:12:53 INFO SecurityManager: Changing view acls to: hadoop
17/12/20 17:12:53 INFO SecurityManager: Changing modify acls to: hadoop
17/12/20 17:12:53 INFO SecurityManager: Changing view acls groups to:
17/12/20 17:12:53 INFO SecurityManager: Changing modify acls groups to:
17/12/20 17:12:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
17/12/20 17:12:53 INFO Utils: Successfully started service 'sparkDriver' on port 44739.
compressShuffle => [spark.shuffle.compress : false]
17/12/20 17:12:53 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/20 17:12:53 INFO SparkEnv: Registering MapOutputTracker
17/12/20 17:12:53 INFO SparkEnv: Registering BlockManagerMaster
17/12/20 17:12:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/12/20 17:12:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/12/20 17:12:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f200820b-04d7-4236-9750-9b97fdd65dcb
17/12/20 17:12:53 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/12/20 17:12:53 INFO SparkEnv: Registering OutputCommitCoordinator
17/12/20 17:12:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/12/20 17:12:53 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.10.43.130:4040
17/12/20 17:12:53 INFO SparkContext: Added JAR file:/home/hadoop/hadoopTest/HiBench/sparkbench/assembly/target/sparkbench-assembly-6.1-SNAPSHOT-dist.jar at spark://10.10.43.130:44739/jars/sparkbench-assembly-6.1-SNAPSHOT-dist.jar with timestamp 1513761173914
17/12/20 17:12:54 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://cluster209-hadoop-master:7077...
17/12/20 17:12:54 INFO TransportClientFactory: Successfully created connection to cluster209-hadoop-master/10.10.43.130:7077 after 25 ms (0 ms spent in bootstraps)
17/12/20 17:12:54 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20171220171254-0009
17/12/20 17:12:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37306.
17/12/20 17:12:54 INFO NettyBlockTransferService: Server created on 10.10.43.130:37306
17/12/20 17:12:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/12/20 17:12:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20171220171254-0009/0 on worker-20171220145248-10.10.43.132-42694 (10.10.43.132:42694) with 4 cores
17/12/20 17:12:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20171220171254-0009/0 on hostPort 10.10.43.132:42694 with 4 cores, 1024.0 MB RAM
17/12/20 17:12:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20171220171254-0009/1 on worker-20171220145325-10.10.43.131-46830 (10.10.43.131:46830) with 4 cores
17/12/20 17:12:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20171220171254-0009/1 on hostPort 10.10.43.131:46830 with 4 cores, 1024.0 MB RAM
17/12/20 17:12:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.10.43.130, 37306, None)
17/12/20 17:12:54 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.43.130:37306 with 366.3 MB RAM, BlockManagerId(driver, 10.10.43.130, 37306, None)
17/12/20 17:12:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171220171254-0009/0 is now RUNNING
17/12/20 17:12:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171220171254-0009/1 is now RUNNING
17/12/20 17:12:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.10.43.130, 37306, None)
17/12/20 17:12:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.10.43.130, 37306, None)
17/12/20 17:12:56 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/12/20 17:12:57 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.43.131:48048) with ID 1
17/12/20 17:12:57 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.43.132:53198) with ID 0
17/12/20 17:12:58 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.43.132:37234 with 366.3 MB RAM, BlockManagerId(0, 10.10.43.132, 37234, None)
17/12/20 17:12:58 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.43.131:35812 with 366.3 MB RAM, BlockManagerId(1, 10.10.43.131, 35812, None)
17/12/20 17:12:58 INFO SparkContext:
******************** [KMDebug] ********************
Init with textFile
17/12/20 17:12:59 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/20 17:12:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 219.1 KB, free 366.1 MB)
17/12/20 17:12:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 366.1 MB)
17/12/20 17:12:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.10.43.130:37306 (size: 20.6 KB, free: 366.3 MB)
17/12/20 17:12:59 INFO SparkContext: Created broadcast 0 from textFile at GraphxNWeight.scala:74
17/12/20 17:13:00 INFO SparkContext: Starting job: saveAsTextFile at GraphxNWeight.scala:112
17/12/20 17:13:00 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/20 17:13:00 INFO FileInputFormat: Total input paths to process : 8
17/12/20 17:13:00 INFO DAGScheduler: Registering RDD 2 (flatMap at GraphxNWeight.scala:74)
17/12/20 17:13:00 INFO DAGScheduler: Registering RDD 12 (mapPartitions at VertexRDD.scala:356)
17/12/20 17:13:00 INFO DAGScheduler: Registering RDD 5 (map at GraphxNWeight.scala:85)
17/12/20 17:13:00 INFO DAGScheduler: Registering RDD 7 (map at GraphxNWeight.scala:87)
17/12/20 17:13:00 INFO DAGScheduler: Registering RDD 20 (mapPartitions at VertexRDDImpl.scala:247)
17/12/20 17:13:00 INFO DAGScheduler: Registering RDD 24 (mapPartitions at GraphImpl.scala:207)
17/12/20 17:13:00 INFO DAGScheduler: Registering RDD 32 (mapPartitions at VertexRDDImpl.scala:247)
17/12/20 17:13:00 INFO DAGScheduler: Registering RDD 36 (mapPartitions at GraphImpl.scala:207)
17/12/20 17:13:00 INFO DAGScheduler: Got job 0 (saveAsTextFile at GraphxNWeight.scala:112) with 8 output partitions
17/12/20 17:13:00 INFO DAGScheduler: Final stage: ResultStage 8 (saveAsTextFile at GraphxNWeight.scala:112)
17/12/20 17:13:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1, ShuffleMapStage 5, ShuffleMapStage 3, ShuffleMapStage 7)
17/12/20 17:13:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1, ShuffleMapStage 5, ShuffleMapStage 3, ShuffleMapStage 7)
17/12/20 17:13:00 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at GraphxNWeight.scala:74), which has no missing parents
17/12/20 17:13:00 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/20 17:13:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.5 KB, free 366.1 MB)
17/12/20 17:13:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.6 KB, free 366.1 MB)
17/12/20 17:13:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.10.43.130:37306 (size: 2.6 KB, free: 366.3 MB)
17/12/20 17:13:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
17/12/20 17:13:00 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at GraphxNWeight.scala:74) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
17/12/20 17:13:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 8 tasks
17/12/20 17:13:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 10.10.43.131, executor 1, partition 0, ANY, 4901 bytes)
17/12/20 17:13:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 10.10.43.132, executor 0, partition 1, ANY, 4901 bytes)
17/12/20 17:13:00 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 10.10.43.131, executor 1, partition 2, ANY, 4901 bytes)
17/12/20 17:13:00 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 10.10.43.132, executor 0, partition 3, ANY, 4901 bytes)
17/12/20 17:13:00 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 10.10.43.131, executor 1, partition 4, ANY, 4901 bytes)
17/12/20 17:13:00 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 10.10.43.132, executor 0, partition 5, ANY, 4901 bytes)
17/12/20 17:13:00 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 10.10.43.131, executor 1, partition 6, ANY, 4901 bytes)
17/12/20 17:13:00 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 10.10.43.132, executor 0, partition 7, ANY, 4901 bytes)
17/12/20 17:13:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.10.43.132:37234 (size: 2.6 KB, free: 366.3 MB)
17/12/20 17:13:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.10.43.132:37234 (size: 20.6 KB, free: 366.3 MB)
17/12/20 17:13:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.10.43.131:35812 (size: 2.6 KB, free: 366.3 MB)
17/12/20 17:13:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.10.43.131:35812 (size: 20.6 KB, free: 366.3 MB)
17/12/20 17:13:18 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 18133 ms on 10.10.43.132 (executor 0) (1/8)
17/12/20 17:13:19 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 18527 ms on 10.10.43.131 (executor 1) (2/8)
17/12/20 17:13:19 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 18881 ms on 10.10.43.132 (executor 0) (3/8)
17/12/20 17:13:19 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 18962 ms on 10.10.43.132 (executor 0) (4/8)
17/12/20 17:13:20 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 19797 ms on 10.10.43.132 (executor 0) (5/8)
17/12/20 17:13:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 20061 ms on 10.10.43.131 (executor 1) (6/8)
17/12/20 17:13:20 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 20325 ms on 10.10.43.131 (executor 1) (7/8)
17/12/20 17:13:24 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 23951 ms on 10.10.43.131 (executor 1) (8/8)
17/12/20 17:13:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
17/12/20 17:13:24 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at GraphxNWeight.scala:74) finished in 23.970 s
17/12/20 17:13:24 INFO DAGScheduler: looking for newly runnable stages
17/12/20 17:13:24 INFO DAGScheduler: running: Set()
17/12/20 17:13:24 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ShuffleMapStage 5, ShuffleMapStage 2, ShuffleMapStage 6, ShuffleMapStage 3, ShuffleMapStage 7, ShuffleMapStage 4, ResultStage 8)
17/12/20 17:13:24 INFO DAGScheduler: failed: Set()
17/12/20 17:13:24 INFO DAGScheduler: Submitting ShuffleMapStage 1 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[12] at mapPartitions at VertexRDD.scala:356), which has no missing parents
17/12/20 17:13:24 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/20 17:13:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.1 KB, free 366.1 MB)
17/12/20 17:13:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KB, free 366.1 MB)
17/12/20 17:13:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.10.43.130:37306 (size: 2.3 KB, free: 366.3 MB)
17/12/20 17:13:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/12/20 17:13:24 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 1 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[12] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
17/12/20 17:13:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 8 tasks
17/12/20 17:13:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 8, 10.10.43.131, executor 1, partition 0, NODE_LOCAL, 4614 bytes)
17/12/20 17:13:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 9, 10.10.43.132, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
17/12/20 17:13:24 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at map at GraphxNWeight.scala:85), which has no missing parents
17/12/20 17:13:24 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 10, 10.10.43.131, executor 1, partition 2, NODE_LOCAL, 4614 bytes)
17/12/20 17:13:24 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 11, 10.10.43.132, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
17/12/20 17:13:24 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 12, 10.10.43.131, executor 1, partition 4, NODE_LOCAL, 4614 bytes)
17/12/20 17:13:24 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 13, 10.10.43.132, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
17/12/20 17:13:24 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 14, 10.10.43.131, executor 1, partition 6, NODE_LOCAL, 4614 bytes)
17/12/20 17:13:24 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 15, 10.10.43.132, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
17/12/20 17:13:24 INFO KMScalaKit:
******************** [KMLogInfo] ********************
codecName: org.apache.spark.io.LZFCompressionCodec

17/12/20 17:13:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.4 KB, free 366.0 MB)
17/12/20 17:13:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
17/12/20 17:13:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.10.43.130:37306 (size: 2.4 KB, free: 366.3 MB)
17/12/20 17:13:24 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
17/12/20 17:13:24 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at map at GraphxNWeight.scala:85) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
17/12/20 17:13:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 8 tasks
17/12/20 17:13:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.10.43.132:37234 (size: 2.3 KB, free: 366.3 MB)
17/12/20 17:13:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.10.43.132:53198
17/12/20 17:13:24 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/20 17:13:24 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/20 17:13:24 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(0): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 35812, None)
uncompressedSizes(0): 156946509
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 156946509


17/12/20 17:13:24 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(1): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 37234, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 156946509
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 156946509


17/12/20 17:13:24 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(2): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 35812, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 156946509
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 156946509


17/12/20 17:13:24 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(3): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 37234, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 156946509
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 156946509


17/12/20 17:13:24 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(4): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 35812, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 156946509
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 156946509


17/12/20 17:13:24 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(5): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 37234, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 156946509
uncompressedSizes(6): 0
uncompressedSizes(7): 0
totalSize: 156946509


17/12/20 17:13:24 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(6): KMGetBlockInfo:
location: BlockManagerId(1, 10.10.43.131, 35812, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 156946509
uncompressedSizes(7): 0
totalSize: 156946509


17/12/20 17:13:24 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses(7): KMGetBlockInfo:
location: BlockManagerId(0, 10.10.43.132, 37234, None)
uncompressedSizes(0): 0
uncompressedSizes(1): 0
uncompressedSizes(2): 0
uncompressedSizes(3): 0
uncompressedSizes(4): 0
uncompressedSizes(5): 0
uncompressedSizes(6): 0
uncompressedSizes(7): 156946509
totalSize: 156946509


17/12/20 17:13:24 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 195 bytes
17/12/20 17:13:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.10.43.131:35812 (size: 2.3 KB, free: 366.3 MB)
17/12/20 17:13:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.10.43.131:48048
17/12/20 17:13:25 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: [B@4a838ab8


17/12/20 17:15:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 16, 10.10.43.131, executor 1, partition 0, NODE_LOCAL, 4614 bytes)
17/12/20 17:15:10 WARN TaskSetManager: Lost task 6.0 in stage 1.0 (TID 14, 10.10.43.131, executor 1): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.Long.valueOf(Long.java:840)
	at scala.runtime.BoxesRunTime.boxToLong(BoxesRunTime.java:69)
	at scala.runtime.ScalaRunTime$.array_apply(ScalaRunTime.scala:77)
	at org.apache.spark.util.collection.OpenHashSet.addWithoutResize(OpenHashSet.scala:145)
	at org.apache.spark.util.collection.OpenHashSet.addWithoutResize$mcJ$sp(OpenHashSet.scala:135)
	at org.apache.spark.graphx.util.collection.GraphXPrimitiveKeyOpenHashMap$mcJI$sp.changeValue$mcJI$sp(GraphXPrimitiveKeyOpenHashMap.scala:103)
	at org.apache.spark.graphx.impl.EdgePartitionBuilder.toEdgePartition(EdgePartitionBuilder.scala:58)
	at org.apache.spark.graphx.EdgeRDD$$anonfun$1.apply(EdgeRDD.scala:110)
	at org.apache.spark.graphx.EdgeRDD$$anonfun$1.apply(EdgeRDD.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

17/12/20 17:15:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.10.43.131:35812 (size: 2.4 KB, free: 366.3 MB)
17/12/20 17:15:16 ERROR TaskSchedulerImpl: Lost executor 1 on 10.10.43.131: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/20 17:15:16 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 8, 10.10.43.131, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/20 17:15:16 WARN TaskSetManager: Lost task 2.0 in stage 1.0 (TID 10, 10.10.43.131, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/20 17:15:16 WARN TaskSetManager: Lost task 4.0 in stage 1.0 (TID 12, 10.10.43.131, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/20 17:15:16 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 16, 10.10.43.131, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/12/20 17:15:16 INFO DAGScheduler: Executor lost: 1 (epoch 1)
17/12/20 17:15:16 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
17/12/20 17:15:16 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 10.10.43.131, 35812, None)
17/12/20 17:15:16 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor
17/12/20 17:15:16 INFO DAGScheduler: Shuffle files lost for executor: 1 (epoch 1)
17/12/20 17:15:16 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 1 (4/8, false)
17/12/20 17:15:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171220171254-0009/1 is now EXITED (Command exited with code 52)
17/12/20 17:15:16 INFO StandaloneSchedulerBackend: Executor app-20171220171254-0009/1 removed: Command exited with code 52
17/12/20 17:15:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20171220171254-0009/2 on worker-20171220145325-10.10.43.131-46830 (10.10.43.131:46830) with 4 cores
17/12/20 17:15:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20171220171254-0009/2 on hostPort 10.10.43.131:46830 with 4 cores, 1024.0 MB RAM
17/12/20 17:15:16 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
17/12/20 17:15:16 INFO BlockManagerMaster: Removal of executor 1 requested
17/12/20 17:15:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 1
17/12/20 17:15:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20171220171254-0009/2 is now RUNNING
17/12/20 17:15:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.43.131:48068) with ID 2
17/12/20 17:15:18 INFO TaskSetManager: Starting task 4.1 in stage 1.0 (TID 17, 10.10.43.131, executor 2, partition 4, NODE_LOCAL, 4614 bytes)
17/12/20 17:15:18 INFO TaskSetManager: Starting task 2.1 in stage 1.0 (TID 18, 10.10.43.131, executor 2, partition 2, NODE_LOCAL, 4614 bytes)
17/12/20 17:15:18 INFO TaskSetManager: Starting task 0.1 in stage 1.0 (TID 19, 10.10.43.131, executor 2, partition 0, NODE_LOCAL, 4614 bytes)
17/12/20 17:15:18 INFO TaskSetManager: Starting task 6.1 in stage 1.0 (TID 20, 10.10.43.131, executor 2, partition 6, NODE_LOCAL, 4614 bytes)
17/12/20 17:15:19 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.43.131:43139 with 366.3 MB RAM, BlockManagerId(2, 10.10.43.131, 43139, None)
17/12/20 17:15:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.10.43.131:43139 (size: 2.3 KB, free: 366.3 MB)
17/12/20 17:15:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.10.43.131:48068
17/12/20 17:15:21 INFO KMScalaKit:
******************** [KMLogInfo] ********************
retBytes: null


17/12/20 17:15:21 INFO KMScalaKit:
******************** [KMLogInfo] ********************
statuses.length: 8


17/12/20 17:15:21 ERROR MapOutputTrackerMaster:
java.lang.NullPointerException
	at org.apache.spark.MapOutputTrackerMaster$$anonfun$getSerializedMapOutputStatuses$1.apply$mcVI$sp(MapOutputTracker.scala:573)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:570)
	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:352)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
